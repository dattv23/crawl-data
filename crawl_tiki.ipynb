{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract info: 'NoneType' object has no attribute 'replace'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract info: 'NoneType' object has no attribute 'replace'\n",
      "Error extract info: 'NoneType' object has no attribute 'replace'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract info: invalid literal for int() with base 10: '1k'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n",
      "Error extract rating: 'NoneType' object has no attribute 'find'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def encode_filename(title):\n",
    "    # Remove any illegal characters from the title\n",
    "    safe_title = \"\".join(c for c in title if c.isalnum() or c in [\" \", \"_\", \"-\"])\n",
    "\n",
    "    # Encode the title using MD5\n",
    "    encoded_title = hashlib.md5(safe_title.encode()).hexdigest()\n",
    "\n",
    "    return encoded_title\n",
    "\n",
    "\n",
    "def extract_info(soup):\n",
    "    try:\n",
    "        # Extract title\n",
    "        title = soup.find(\n",
    "            \"h1\", class_=\"Title__TitledStyled-sc-c64ni5-0 iXccQY\"\n",
    "        ).text.strip()\n",
    "\n",
    "        # Extract author's name\n",
    "        author_tag = soup.find(\"a\", {\"data-view-id\": \"pdp_details_view_author\"})\n",
    "        author_name = author_tag.text.strip() if author_tag else None\n",
    "\n",
    "        # Extract image URL from <source> tag\n",
    "        imageDiv = soup.find(\n",
    "            \"div\", class_=\"style__ProductImagesStyle-sc-15sdfel-0 kXwtNH\"\n",
    "        )\n",
    "        image_tag = imageDiv.find(\"source\") if imageDiv else None\n",
    "\n",
    "        if image_tag and \"srcset\" in image_tag.attrs:\n",
    "            srcset = image_tag[\"srcset\"]\n",
    "            image_url = (\n",
    "                srcset.split(\",\")[0].strip().split(\" \")[0]\n",
    "            )  # Take the first URL before \" 1x\"\n",
    "        else:\n",
    "            image_url = None\n",
    "\n",
    "        # Extract sold quantity\n",
    "        sold_tag = soup.find(\"div\", {\"data-view-id\": \"pdp_quantity_sold\"})\n",
    "        sold_quantity = (\n",
    "            sold_tag.text.strip().replace(\"Đã bán \", \"\") if sold_tag else None\n",
    "        )\n",
    "\n",
    "        # Extract price\n",
    "        price_tag = soup.find(\"div\", class_=\"product-price__current-price\")\n",
    "        current_price = price_tag.text.strip() if price_tag else None\n",
    "\n",
    "        # Extract original price\n",
    "        try:\n",
    "            original_price_tag = soup.find(\n",
    "                \"div\", class_=\"product-price__original-price\"\n",
    "            ).find(\"del\")\n",
    "\n",
    "            # Extracting the text, if the <del> tag exists\n",
    "            original_price = (\n",
    "                original_price_tag.text.strip() if original_price_tag else None\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"title\": title,\n",
    "                \"author\": author_name,\n",
    "                \"imageUrl\": image_url,\n",
    "                \"soldQuantity\": int(sold_quantity),\n",
    "                \"currentPrice\": int(current_price.replace(\"₫\", \"\").replace(\".\", \"\")),\n",
    "                \"originalPrice\": int(current_price.replace(\"₫\", \"\").replace(\".\", \"\")),\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"author\": author_name,\n",
    "            \"imageUrl\": image_url,\n",
    "            \"soldQuantity\": int(sold_quantity.replace(\"k\", \"000\")),\n",
    "            \"currentPrice\": int(current_price.replace(\"₫\", \"\").replace(\".\", \"\")),\n",
    "            \"originalPrice\": int(\n",
    "                original_price.replace(\".\", \"\"),\n",
    "            ),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error extract info: {e}\")  # Optional: print the error for debugging\n",
    "        return {}\n",
    "\n",
    "\n",
    "def extract_rating(soup):\n",
    "    try:\n",
    "        rating_summary = soup.find(\"div\", class_=\"review-rating__inner\")\n",
    "        total_rating = float(\n",
    "            rating_summary.find(\"div\", class_=\"review-rating__point\").get_text(\n",
    "                strip=True\n",
    "            )\n",
    "        )\n",
    "        number_of_ratings_text = rating_summary.find(\n",
    "            \"div\", class_=\"review-rating__total\"\n",
    "        ).get_text(strip=True)\n",
    "        number_of_ratings = int(\"\".join(filter(str.isdigit, number_of_ratings_text)))\n",
    "\n",
    "        return {\"totalRating\": total_rating, \"numberOfRating\": number_of_ratings}\n",
    "    except Exception as e:\n",
    "        print(f\"Error extract rating: {e}\")  # Optional: print the error for debugging\n",
    "        return {}\n",
    "\n",
    "\n",
    "def extract_reviews(soup):\n",
    "    try:\n",
    "        reviews = soup.find_all(\n",
    "            \"div\", class_=\"style__StyledComment-sc-1y8vww-5 dpVjwc review-comment\"\n",
    "        )\n",
    "        review_data = []\n",
    "        for review in reviews:\n",
    "            # Extract user information\n",
    "            user_name = review.find(\"div\", class_=\"review-comment__user-name\").get_text(\n",
    "                strip=True\n",
    "            )\n",
    "            user_date = review.find(\"div\", class_=\"review-comment__user-date\").get_text(\n",
    "                strip=True\n",
    "            )\n",
    "\n",
    "            # Extract review count and liked count\n",
    "            user_info_divs = review.find_all(\"div\", class_=\"review-comment__user-info\")\n",
    "            review_count = user_info_divs[0].find(\"span\").get_text(strip=True)\n",
    "            liked_count = user_info_divs[1].find(\"span\").get_text(strip=True)\n",
    "\n",
    "            # Extract review title\n",
    "            review_title = review.find(\"div\", class_=\"review-comment__title\").get_text(\n",
    "                strip=True\n",
    "            )\n",
    "\n",
    "            # Determine rating based on review title\n",
    "            if review_title == \"Cực kì hài lòng\":\n",
    "                rating = 5\n",
    "            elif review_title == \"Hài lòng\":\n",
    "                rating = 4\n",
    "            elif review_title == \"Bình thường\":\n",
    "                rating = 3\n",
    "            elif review_title == \"Không hài lòng\":\n",
    "                rating = 2\n",
    "            else:\n",
    "                rating = 1\n",
    "\n",
    "            # Extract review content\n",
    "            review_content = review.find(\n",
    "                \"div\", class_=\"review-comment__content\"\n",
    "            ).get_text(strip=True)\n",
    "\n",
    "            review_data.append(\n",
    "                {\n",
    "                    \"reviewer\": {\n",
    "                        \"name\": user_name,\n",
    "                        \"date\": user_date,\n",
    "                        \"reviewCount\": review_count,\n",
    "                        \"likedCount\": liked_count,\n",
    "                    },\n",
    "                    \"review\": {\n",
    "                        \"rating\": rating,\n",
    "                        \"title\": review_title,\n",
    "                        \"content\": review_content,\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "        return review_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error extract review: {e}\")  # Optional: print the error for debugging\n",
    "        return {}\n",
    "\n",
    "\n",
    "def extract_details(soup):\n",
    "    try:\n",
    "        details = {}\n",
    "        # Find all divs with class 'WidgetTitle__WidgetContentStyled-sc-12sadap-2'\n",
    "        content_divs = soup.find_all(\n",
    "            \"div\", class_=\"WidgetTitle__WidgetContentStyled-sc-12sadap-2 hNNYbU\"\n",
    "        )\n",
    "\n",
    "        map = {\n",
    "            \"Công ty phát hành\": \"publisher\",\n",
    "            \"Kích thước\": \"dimensions\",\n",
    "            \"Dịch Giả\": \"translator\",\n",
    "            \"Loại bìa\": \"coverType\",\n",
    "            \"Số trang\": \"pageCount\",\n",
    "            \"Nhà xuất bản\": \"publishingHouse\",\n",
    "            \"Ngày xuất bản\": \"publishDate\",\n",
    "            \"Phiên bản sách\": \"bookVersion\",\n",
    "        }\n",
    "\n",
    "        for div in content_divs:\n",
    "            # Get the label and value spans\n",
    "            label_span = div.find(\n",
    "                \"span\", style=\"max-width: 300px; color: rgb(128, 128, 137);\"\n",
    "            )\n",
    "            value_span = div.find(\n",
    "                \"span\", class_=\"styles__ProductAttributeValueStyled-sc-vjutbk-0 chhHdv\"\n",
    "            )\n",
    "\n",
    "            if label_span and value_span:\n",
    "                # Extract label and value text\n",
    "                label = label_span.text.strip()\n",
    "                value = value_span.text.strip()\n",
    "\n",
    "                # Store label and value in details dictionary\n",
    "                details[map.get(label) if map.get(label) is not None else label] = value\n",
    "\n",
    "        return details\n",
    "    except Exception as e:\n",
    "        print(f\"Error extract details: {e}\")  # Optional: print the error for debugging\n",
    "        return {}\n",
    "\n",
    "\n",
    "def extract_description_product(soup):\n",
    "    try:\n",
    "        content_div = soup.find(\"div\", class_=\"ToggleContent__View-sc-fbuwol-0 imwRtb\")\n",
    "        if not content_div:\n",
    "            return \"\"\n",
    "        paragraphs = content_div.find_all(\"p\")\n",
    "        # Join all paragraphs as a single introduction text\n",
    "        introduction = \"\\n\".join(p.get_text(strip=True) for p in paragraphs)\n",
    "\n",
    "        return introduction\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"Error extract description: {e}\"\n",
    "        )  # Optional: print the error for debugging\n",
    "        return {}\n",
    "\n",
    "\n",
    "categories = [\n",
    "    \"https://tiki.vn/sach-kien-thuc-tong-hop/c873\",\n",
    "]\n",
    "\n",
    "\n",
    "def extract_books_from_category(base_dir, url):\n",
    "    # Extract the category name from the URL\n",
    "    category_name = url.split(\"/\")[-2]\n",
    "\n",
    "    # Create a directory for the category\n",
    "    category_dir = os.path.join(base_dir, category_name)\n",
    "    if not os.path.exists(category_dir):\n",
    "        os.makedirs(category_dir)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    ActionChains(driver).scroll_by_amount(0, 800).perform()\n",
    "\n",
    "    # Wait until the presence of at least one element with data-view-id=\"product_list_item\"\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    a_tags = wait.until(\n",
    "        EC.presence_of_all_elements_located(\n",
    "            (By.CSS_SELECTOR, 'a[data-view-id=\"product_list_item\"]')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Now you can proceed to extract data from the a_tags\n",
    "    # For example:\n",
    "    urls = []\n",
    "    for a_tag in a_tags:\n",
    "        href = a_tag.get_attribute(\"href\")\n",
    "        urls.append(href)\n",
    "\n",
    "    for url in urls:\n",
    "        try:\n",
    "            # Load the webpage\n",
    "            driver.get(url)\n",
    "            # Wait for 3 seconds\n",
    "            time.sleep(3)\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            info_data = extract_info(soup)\n",
    "            # Get the title\n",
    "            title = info_data[\"title\"]\n",
    "            filename = os.path.join(category_dir, f\"{encode_filename(title)}.json\")\n",
    "            if os.path.exists(filename):\n",
    "                continue\n",
    "            time.sleep(3)\n",
    "\n",
    "            # Scroll to the details section\n",
    "            ActionChains(driver).scroll_by_amount(0, 2000).perform()\n",
    "            time.sleep(3)\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            details = extract_details(soup)\n",
    "\n",
    "            time.sleep(3)\n",
    "            description = extract_description_product(soup)\n",
    "\n",
    "            # Scroll to the desired section\n",
    "            ActionChains(driver).scroll_by_amount(0, 1300).perform()\n",
    "            time.sleep(3)\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            rating = extract_rating(soup)\n",
    "            review_data = []\n",
    "\n",
    "            try:\n",
    "                btn_next = driver.find_element(\n",
    "                    By.CSS_SELECTOR,\n",
    "                    \"#customer-review-widget-id > div > div.style__StyledCustomerReviews-sc-1y8vww-0.gCaHEu.customer-reviews > div > div.customer-reviews__pagination > ul > li:nth-child(7) > a\",\n",
    "                )\n",
    "\n",
    "                while btn_next:\n",
    "                    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                    data = extract_reviews(soup)\n",
    "                    if data == []:\n",
    "                        break\n",
    "                    review_data.extend(data)\n",
    "                    actions = ActionChains(driver)\n",
    "                    actions.move_to_element(btn_next)\n",
    "                    actions.click(btn_next)\n",
    "                    actions.perform()\n",
    "                    time.sleep(3)\n",
    "            except:\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                data = extract_reviews(soup)\n",
    "                review_data.extend(data)\n",
    "            finally:\n",
    "                # Generate filename\n",
    "                filename = os.path.join(category_dir, f\"{encode_filename(title)}.json\")\n",
    "                data = {\n",
    "                    \"info\": info_data,\n",
    "                    \"details\": details,\n",
    "                    \"description\": description,\n",
    "                    \"rating\": rating,\n",
    "                    \"reviews\": review_data,\n",
    "                }\n",
    "\n",
    "                # Save the extracted data to a JSON file\n",
    "                with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "# Ensure the base directory exists\n",
    "base_dir = \"tiki\"\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "for category in categories:\n",
    "    try:\n",
    "        extract_books_from_category(base_dir=base_dir, url=category)\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
